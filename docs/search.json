[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Guías de R para Econometría",
    "section": "",
    "text": "Pendiente!\n\n\n\nEl aprender de los elementos de R son cruciales para desarrollar los proyectos del curso.",
    "crumbs": [
      "Guías de R para Econometría"
    ]
  },
  {
    "objectID": "index.html#bienvenidos",
    "href": "index.html#bienvenidos",
    "title": "Guías de R para Econometría",
    "section": "Bienvenidos!",
    "text": "Bienvenidos!\nEconometría I es un curso introductorio que proporciona los fundamentos para analizar datos económicos utilizando métodos estadísticos y matemáticos. Es dado en el quinto semestre de los estudiantes del departamento de Economía de la Universidad del Norte   El curso busca desarrollar habilidades para:\n\n\n\n\n\n\n\n\n\n\nConstrucción de modelos teóricos para explicar fenómenos económicos.\nUtilización de datos para estimar los valores de los parámetros de los modelos económicos.\nRealización de pruebas de hipótesis para evaluar la validez de los modelos económicos.\nAplicación de técnicas de regresión lineal para analizar la relación entre variables económicas.\nEstudio de la evolución de variables económicas a lo largo del tiempo.\nUso de lenguaje como R para llevar a cabo análisis cuantitativo.\n\n\n\n\n\n\n\n\n\n\nEmpezamos\n\n\n\nEmpiece con la lección 1 de una vez! ahi encontrará como instalar R y mirar su interfaz.",
    "crumbs": [
      "Guías de R para Econometría"
    ]
  },
  {
    "objectID": "index.html#su-profesor",
    "href": "index.html#su-profesor",
    "title": "Guías de R para Econometría",
    "section": "Su Profesor",
    "text": "Su Profesor\n\n\n\n\n\n\nSoy Carlos Yanes, Economista de la Universidad de Cartagena. A lo largo de mi carrera me he interesado en temas estadísticos y matemáticos aplicados a las ciencias sociales.\n\n\n\n\n\nCarlos Yanes",
    "crumbs": [
      "Guías de R para Econometría"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#limitaciones",
    "href": "lecciones/unidad01.html#limitaciones",
    "title": "1: Empecemos",
    "section": "Limitaciones",
    "text": "Limitaciones\nComo todo software (programa) R posee limitaciones, primeramente es un lenguaje que fue desarrollado en la década de los 80’s y cuando aun no estaba en pleno el Internet y no había mucho desarrollo tecnológico. Entre algunas limitaciones podemos resaltar:\n\nUso de memoria física alto.\nMontón de paquetes denominados packages y que no son nada uniformes\nCon bases de datos enormes (big data) se queda corto y hay que hacer uso de Spark u otros softwares que tienen que ver con SQL.",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#primeros-pasos",
    "href": "lecciones/unidad01.html#primeros-pasos",
    "title": "1: Empecemos",
    "section": "Primeros pasos",
    "text": "Primeros pasos\nLo primero es ir a la pagina de https://www.r-project.org e ir a la pestaña de CRAN y descargar la versión de acuerdo al sistema operativo que usted tenga, llamese Linux, Windows o IOS.\n\nDespues de haber instalado el programa, urge ir al link de R Studio que es un potente aliado1 en el entorno de ejecución del programa R, se le denomina IDE Por sus siglas en ingles significa Integrated Drive Electronics, no es mas que un entorno de desarrollo interactivo que facilita interactuar mejor y de manera mas “amigable” con todos los asuntos de los lenguajes de programación.\n\nDebe ir por lo pronto a la sección free, esperar el tiempo de acuerdo a la velocidad de conexión y luego ejecutarlo. Ya después de eso podrá interactuar mejor con R y visualmente todo será mejor para el trabajo.",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#script-bitacoras",
    "href": "lecciones/unidad01.html#script-bitacoras",
    "title": "1: Empecemos",
    "section": "Script (Bitacoras)",
    "text": "Script (Bitacoras)\nSiempre es bueno crear unas notas de código. Es una especie de cuaderno que le permite tener apuntes o escritos para saber que va haciendo linea a linea, incluso le sirve como un historial de desarrollo, de todas maneras R tiene su propio, pero es altamente recomendable que usted lo maneje de esta forma. Lo puede hacer en formato texto o txt del block de notas en su sistema operativo o también directamente desde el programa de R studio solo presionando las teclas ctrl+shift+N o de esta manera en el menú principal:\n\nNote que R Studio trabaja con 3 ventanas principales, estas son la de consola, Environment y File, todas tienen sus respectivas pestañas que le serán funcionales a la hora de hacer sus proyectos.\n\ndi_tu_nombre &lt;- function (nombre) {\n  paste(\"Hola y bienvenido(a),\", nombre, \"! al curso de econometría I\")\n}\ndi_tu_nombre(\"Carlos Andrés\")\n\n[1] \"Hola y bienvenido(a), Carlos Andrés ! al curso de econometría I\"\n\n\nLo anterior es un ejemplo de las múltiples funcionalidades que tiene el programa de R y puede incluso crear sus propios comandas a partir de la opción de function.",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#paquetes",
    "href": "lecciones/unidad01.html#paquetes",
    "title": "1: Empecemos",
    "section": "Paquetes",
    "text": "Paquetes\nEl programa de R contiene muchas funciones o formulas que ya vienen códificadas dentro de un conjunto de operaciones que se van a denominar paquetes. Estos deben ser instalados solo una vez y luego cada vez que vayan a ser usados deben cargarse con la función u orden library.\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#primeros-cálculos",
    "href": "lecciones/unidad01.html#primeros-cálculos",
    "title": "1: Empecemos",
    "section": "Primeros cálculos",
    "text": "Primeros cálculos\nPara esta parte del curso, se establecerán algunos cálculos y operaciones básicas ya mostradas en los vídeos tutoriales de la clase y que se encuentran alojados en la carpeta de contenido en el blackboard. Esta primera parte solo tiene cálculos básicos y operaciones de tipo calculadora tal cual el programa así lo permite. Ejemplo:\n\n  452+100 # Una suma o adición\n  1455*sqrt(12) # Producto con la raíz cuadrada de 12\n  15**2 # Potencia de un número\n  300/30 # Simple división\n\nNote que el (#) es para decirle al programa que no ejecute lo que se encuentra después de él, se usa para tomar notas o escribir algo al respecto, por ejemplo:\n\n# Soy carlos yanes\n\nPara la parte de asignación de valores a una variable (X) -puede darle el nombre que le desee colocar- se tiene que:\n\n  a&lt;-2\n  a=2 # También se puede usar el igual\n  a^2 # El cuadrado de esa variable\n  abs(a) # Valor absoluto de la variable\n  sqrt(a) # Raíz cuadrada de la variable\n  log(a) # Logaritmo natural\n  log(a,b) # Logaritmo con base al valor b correspondiente,\n  exp(a) # Valor Exponencial de a\n  factorial(a) # Factor de a\n\nRecuerde que en R todo es un objeto y hay que ir asignando de cierta forma a lo que venimos trabajando, es la manera para ser organizados y no perder de vista calculos que se vienen desarrollando en la lista de aprendizaje.\nEn economía y en muchas ciencias sociales se hace uso extensivo de las matemáticas y de la estadística. Muchas veces será incluso necesario calcular o realizar algunas transformaciones en las variables para poder tener unas métricas mas informativas como son los logaritmos, valores absolutos, valores de forma exponencial o de notación científica, entre otros. Algunos comandos que se pueden usar en R para eso son:\n\n\n\nOperación\nResultado\n\n\n\n\nValor absoluto\nabs()\n\n\nLogaritmo\nlog()\n\n\nLogaritmo base\nlog(,)\n\n\nExponencial\nexp()\n\n\nFactorial\nfactorial()\n\n\nRaíz cuadrada\nsqrt()\n\n\n\nEl valor absoluto de un número como por ejemplo puede ser simplemente:\n\n  abs(-29) # Es el valor absoluto de (-29)\n\n[1] 29\n\n\nSin embargo, en una operación conjunta, si se posee una lista de elementos o un vector de elementos, es mucho mas simple implementarlo de tal forma que:\n\n  x&lt;-c(-26,-21,15,-11,-16,18,21,-31,-33, -24) # Lista de valores\n  abs(x)\n\n [1] 26 21 15 11 16 18 21 31 33 24\n\n\nDe igual forma, funciona con un logaritmo o también una operación que involucre una de forma de notación científica o exponencial, esto puede notarse así:\n\n  y&lt;-c(15,21,23,29,16,28,32,45,33) # Lista de valores para vector Y\n  log(y) #Se calcula el logaritmo de cada uno de los elementos\n\n[1] 2.708050 3.044522 3.135494 3.367296 2.772589 3.332205 3.465736 3.806662\n[9] 3.496508\n\n\nObserve que el Programa calcula el logaritmo natural de cada uno de los elementos del vector (y). Para la forma exponencial, es de uso de la notación del logaritmo base e y que muchos conocen como la expresión de Euler, e.g: \\(e^{x}\\), recuerde ademas que si este lo usamos de tal manera que \\(Y=ln(e^{x})=x\\). Un ejemplo de aplicación es el siguiente:\n\\[e^{150}=?\\]\n\nx&lt;-150 # Asignamos un valor a la expresión (x) \nexp(x) # En R exp hace referencia a la formula de (e)\n\n[1] 1.39371e+65\n\n\nTeniendo la asignación de valores a un objeto en R, podemos simplificar el uso o calculo de forma considerable.\nOtro ejemplo es el siguiente:\n\nx&lt;-300\nalgo.que.quiero.escribir&lt;-700\nx*algo.que.quiero.escribir\n\n[1] 210000\n\n\nRemover objetos en R requiere de la opción de rm() p.e:\n\nrm(x)\n\nSi su deseo el limpiar todo el Environment puede hacer uso de rm() y conjuntamente ls()\n\nrm(list=ls())",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#ambiente-de-elementos",
    "href": "lecciones/unidad01.html#ambiente-de-elementos",
    "title": "1: Empecemos",
    "section": "Ambiente de elementos",
    "text": "Ambiente de elementos\nEn R hay distintas formas y maneras de ver variables o asignarlas a un objeto. Con respecto a eso, podemos entonces comenzar a mirar los distintos tipos de variables y datos que tenemos en el entorno de trabajo:\n\nx &lt;- c(0.55, 0.72)     ## numérico\nx &lt;- c(TRUE, FALSE)    ## lógico\nx &lt;- c(T, F)           ## lógico\nx &lt;- c(\"a\", \"b\", \"c\")  ## cadena\nx &lt;- 15:28              ## entero\nx &lt;- c(1+0i, 2+3i)     ## complejo\n\nCon el objeto igual de saber la clasificación del valor en R usted puede hacer uso del comando class. P.e: si tengo la siguiente secuencia:\n\\[x=\\{ 8,9,10,11,\\cdots,30\\}\\] Entonces le decimos a R lo siguiente\n\nx&lt;-8:30\nclass(x)\n\n[1] \"integer\"\n\n\nConvertir un objeto a otro formato o tipo se puede hacer con la opción de as.numeric y cualquiera de los tipos que se establecieron como ejemplo anteriormente.\n\nas.numeric(x)\n\n [1]  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#análisis-de-vectores",
    "href": "lecciones/unidad01.html#análisis-de-vectores",
    "title": "1: Empecemos",
    "section": "Análisis de vectores",
    "text": "Análisis de vectores\nMuchas veces los vectores se convierten o consideran como una lista de elementos que finalmente constituyen una columna de una base de datos o dataframe. Para mirar un juego de esto, mire el código a continuación:\n\n# Definimos un vector x para todos los años:\nanos&lt;- c(2018,2019,2020,2021,2022,2023)\n# Definimos una matriz de y valores:\nproducto1&lt;-c(10,13,16,19,17,18); producto2&lt;-c(21,32,43,15,19,36); producto3&lt;-c(22,43,42,21,32,21)\n# Una forma de unir vectores es con el comando cbind\nventas_mat &lt;- cbind(producto1,producto2,producto3) \n# Nombramos las filas con el vector de años:\nrownames(ventas_mat) &lt;- anos \n# La matriz de datos es:\nventas_mat\n\n     producto1 producto2 producto3\n2018        10        21        22\n2019        13        32        43\n2020        16        43        42\n2021        19        15        21\n2022        17        19        32\n2023        18        36        21\n\n\nOtra manera o forma de crear datos en R es involucrando los nombres de personas que entrevistamos y obtenemos sus datos. Estos vienen en formato de caracteres y otros de forma numérica. Recuerde que combinar cada uno de los vectores (columnas) se hace con la función cbind que es una especie de (“merge”) o de unión de múltiples elementos (columnas) para formar adecuadamente una base de datos.\n\n# Definimos un vector x para todos los individuos:\nindividuos&lt;- c(\"Carlos\", \"Jose\", \"Maria\", \"Susana\")\nedad&lt;-c(29,41,28,29); estrato&lt;-c(3,4,3,2); civil&lt;-c(1,1,2,3)\ndatos_mat &lt;- cbind(edad,estrato,civil) \nrownames(datos_mat) &lt;- individuos \ndatos_mat\n\n       edad estrato civil\nCarlos   29       3     1\nJose     41       4     1\nMaria    28       3     2\nSusana   29       2     3\n\n\nSi por ejemplo queremos el promedio de edad de las personas, es fácil en R decir:\n\nmean(edad)\n\n[1] 31.75",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#factores-variables-cualitativas",
    "href": "lecciones/unidad01.html#factores-variables-cualitativas",
    "title": "1: Empecemos",
    "section": "Factores (variables cualitativas)",
    "text": "Factores (variables cualitativas)\nEn las ciencias sociales siempre es útil tener en cuenta las variables de corte cualitativo, como el genero, estado civil. el tratamiento ideal para esto es haciendo uso del comando o función factor, P.e:\n\nx&lt;- factor(c(\"Masculino\", \"Femenino\", \"Binario\", \"Masculino\", \"Masculino\", \"Femenino\"))\ntable(x) # Para calcular la frecuencia\n\nx\n  Binario  Femenino Masculino \n        1         2         3 \n\n\nSi por algún motivo queremos extraer o tener valores numéricos de las variables podemos entonces tener:\n\nunclass(x)\n\n[1] 3 2 1 3 3 2\nattr(,\"levels\")\n[1] \"Binario\"   \"Femenino\"  \"Masculino\"\n\n\nTambién, se puede hacer a la inversa. Esto es tener la lista o número de valores y luego proceder con el “etiquetado”. En el programa son conocido como niveles o levels. Para mostrar un ejemplo de eso, entonces tendremos:\n\n# Primero tenemos nuestra variable\ny&lt;-c(2,2,3,4,5,4,2,1,1,2,5,4,4,3)\n# Se especifican las etiquetas en el orden correspondiente\nfactor_y &lt;- factor(y, labels = c(\"Pesimo\", \"Malo\",\n                                \"Regular\", \"Bueno\", \"Excelente\"))\n# Miramos el resultado\nfactor_y\n\n [1] Malo      Malo      Regular   Bueno     Excelente Bueno     Malo     \n [8] Pesimo    Pesimo    Malo      Excelente Bueno     Bueno     Regular  \nLevels: Pesimo Malo Regular Bueno Excelente",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad01.html#footnotes",
    "href": "lecciones/unidad01.html#footnotes",
    "title": "1: Empecemos",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPara mayor información consulte la pagina web o enlace de R Studio.↩︎",
    "crumbs": [
      "Parte 1",
      "1: Empecemos"
    ]
  },
  {
    "objectID": "lecciones/unidad02.html#video",
    "href": "lecciones/unidad02.html#video",
    "title": "2: Datos",
    "section": "Video",
    "text": "Video",
    "crumbs": [
      "Parte 1",
      "2: Datos"
    ]
  },
  {
    "objectID": "lecciones/unidad02.html#chunks",
    "href": "lecciones/unidad02.html#chunks",
    "title": "2: Datos",
    "section": "Chunks",
    "text": "Chunks\nEl siguiente elemento son los chunks estos son una especie de integrador del código del programa con elementos del formato en el cual este redactando o haciendo un informe de Markdown.\n\nEs importante tener presente cada uno de los elementos que conforman el chunk, ademas de colocarle un nombre único comentarios y las opciones de estos.",
    "crumbs": [
      "Parte 1",
      "2: Datos"
    ]
  },
  {
    "objectID": "lecciones/unidad02.html#operador-pipe",
    "href": "lecciones/unidad02.html#operador-pipe",
    "title": "2: Datos",
    "section": "Operador Pipe",
    "text": "Operador Pipe\nEl operador pipe %&gt;% ayuda a simplificar las lineas de código de tal manera que condensa o adjunta múltiples ordenes en pocas lineas:\ny&lt;- mean(log(x)) # Es similar a\ny&lt;- x %&gt;% log %&gt;% mean\nEn sintesis organiza las ordenes del código, lo anterior dice que con el objeto de x calcule el logaritmo y luego el promedio. Otro ejemplo o secuencia es:\nMire la siguiente linea bastante compleja en R si se opta por no usar el operador. Asuma la siguiente orden: Encuentre las llaves, desbloquea, maneja el carro hasta la U y finalmente parquea.\nparquea(conduce(prender_carro(encuentra(\"llaves\")),a= \"Universidad\"))\nCuando usa el operador %&gt;% la orden es mucho mejor y puede escribirla como:\nencuentra(\"llaves\") %&gt;%\n  prender_carro() %&gt;%\n  conduce(a= \"Universidad\")\n  parquea()\nDe esta manera es mas limpio y claro lo anterior. Para hacer uso del operador es recomendable haber instalado el paquete tidyverse.",
    "crumbs": [
      "Parte 1",
      "2: Datos"
    ]
  },
  {
    "objectID": "lecciones/unidad02.html#paquete-dplyr",
    "href": "lecciones/unidad02.html#paquete-dplyr",
    "title": "2: Datos",
    "section": "Paquete dplyr",
    "text": "Paquete dplyr\nCon tidyverse también puede gestionar estadísticas, esto lo puede hacer con los comandos que se exponen a continuación:\n\nsummarise(Pruebadatos, Promedio=mean(Consumo))\n\n# A tibble: 1 × 1\n  Promedio\n     &lt;dbl&gt;\n1     24.3\n\n\nLo anterior nos brinda en un estilo de \\(\\bar{x}\\) de forma única o solo para una variable. Si queremos mirar en grupo.\n\nsummarise_each(Pruebadatos, funs(mean))\n\n# A tibble: 1 × 3\n  Consumo Ingreso Precios\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1    24.3 889143.   4922.\n\n\nY con eso tendremos todas los promedios del caso. Hay otras opciones dentro de las funciones de dplyr para hallar valor mínimo o (min), el máximo, la varianza, entre otros.",
    "crumbs": [
      "Parte 1",
      "2: Datos"
    ]
  },
  {
    "objectID": "lecciones/unidad02.html#paquete-skimr",
    "href": "lecciones/unidad02.html#paquete-skimr",
    "title": "2: Datos",
    "section": "Paquete skimr",
    "text": "Paquete skimr\nLo anterior también puede hacerlo con el paquete de skimr, que compila e incluso llega a gráficar. Para hacer uso de él debe establecer\n\nlibrary(skimr)\nskim(Pruebadatos)\n\n\nData summary\n\n\nName\nPruebadatos\n\n\nNumber of rows\n9\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nConsumo\n0\n1\n24.33\n10.77\n10\n16\n25\n30\n45\n▆▂▇▁▂\n\n\nIngreso\n0\n1\n889142.67\n153511.64\n532900\n840200\n956920\n998564\n999300\n▂▁▂▃▇\n\n\nPrecios\n0\n1\n4922.22\n330.82\n4500\n4700\n4800\n5200\n5400\n▅▇▁▅▅",
    "crumbs": [
      "Parte 1",
      "2: Datos"
    ]
  },
  {
    "objectID": "lecciones/unidad02.html#histogramas",
    "href": "lecciones/unidad02.html#histogramas",
    "title": "2: Datos",
    "section": "Histogramas",
    "text": "Histogramas\nEl histograma es uno de los primeros gráficos de uso para conocer mejor el punto de la distribución de variables. Con esto nos indica que proporción de observaciones contiene una característica en particular. Los histogramas pueden señalar que tan asimétricos son las observaciones y si existe o no un sesgo en la cola de la distribución.\n\n# Extraer datos para un vector\nPRS &lt;- Pruebadatos$Consumo\n\n# Figura (a): histograma (para orden y conteo)\nhist(PRS)\n\n\n\n\n\n\n\n# Densidad de la variable y aplicación con colores\nd &lt;- density(PRS)\nplot(d, main=\"Densidad Kernel del Consumo\")\npolygon(d, col=\"blue\", border=\"red\") \n\n\n\n\n\n\n\n#Densidad con Histograma\nx &lt;- Pruebadatos$Consumo\nh&lt;-hist(x, breaks=5, col=\"blue\", xlab=\"Consumo en unidades\", ylab = \"Frecuencia de consumo\",\n        main=\"Histograma con curva de la dist. Normal\")\nxfit&lt;-seq(min(x),max(x),length=40)\nyfit&lt;-dnorm(xfit,mean=mean(x),sd=sd(x))\nyfit &lt;- yfit*diff(h$mids[1:2])*length(x)\nlines(xfit, yfit, col=\"red\", lwd=2)\n\n\n\n\n\n\n\n\nDe lo anterior notamos que el consumo tiene una asimetría positiva (la cola de la distribución esta a la derecha) y tiene algunos datos en esa zona. Aunque hay una proporción de personas (40%) que contiene un consumo entre las 15 a 30 unidades respectivamente.",
    "crumbs": [
      "Parte 1",
      "2: Datos"
    ]
  },
  {
    "objectID": "lecciones/unidad02.html#con-respecto-a-los-gráficos",
    "href": "lecciones/unidad02.html#con-respecto-a-los-gráficos",
    "title": "2: Datos",
    "section": "Con respecto a los gráficos",
    "text": "Con respecto a los gráficos\nRecuerde que los gráficos que provee R como base son muy buenos, sin embargo puede usar otros paquetes como el de ggplot que tambien contiene otras mejoras visuales.\n\nlibrary(ggplot2)\nggplot(Pruebadatos, aes(x = Consumo)) +\n  geom_histogram()\n\n\n\n\n\n\n\n# Con barras que decide el(la) autor(a) `binwidth`\nggplot(Pruebadatos, aes(x = Consumo)) +\n  geom_histogram(binwidth = 4)",
    "crumbs": [
      "Parte 1",
      "2: Datos"
    ]
  },
  {
    "objectID": "lecciones/unidad02.html#footnotes",
    "href": "lecciones/unidad02.html#footnotes",
    "title": "2: Datos",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEn la pestaña de files del menú inferior se encuentra la tuerquita (more) que le da la opción de directorio de trabajo↩︎\nRecuerde que para instalar programas debe hacer uso del comando install.packages(\"tidyverse\")↩︎\nSe creo una nueva base (df), pero también puede usar la misma.↩︎",
    "crumbs": [
      "Parte 1",
      "2: Datos"
    ]
  },
  {
    "objectID": "lecciones/unidad03.html#integrabilidad-y-función-de-probabilidad-de-una-variable-continua",
    "href": "lecciones/unidad03.html#integrabilidad-y-función-de-probabilidad-de-una-variable-continua",
    "title": "3: Distribución de datos",
    "section": "Integrabilidad y Función de probabilidad de una variable continua",
    "text": "Integrabilidad y Función de probabilidad de una variable continua\n-Recuerde en clases- que si queríamos conocer la función de probabilidad de una variable continua como (x) entonces es posible plantear mediante una integral y calcular el área bajo la curva de una función continua:\n\\[\\int_{a}^{b} f (x) dx= P( a \\leq x\\leq b )\\] Todo lo anterior es con la posibilidad de conocer cual es la probabilidad de que \\((x)\\) se encuentre en cierto rango de valores entre \\(a\\) y \\(b\\) siendo estos los límites inferiores y superiores de la integral. En R podemos implementarlo de la siguiente manera:\n\nintegrate(function(x) x, lower = 0, upper = 1)\n# Lower es el limite inferior y upper el superior\n\nProcedemos hallar la probabilidad que \\(f(x)=\\frac{1}{x^2}\\) se encuentre entre el límite inferior de \\(a=1\\) y el límite superior de \\(b=\\infty^+\\).\n\n# Hallar el área bajo la curva\narea &lt;- integrate(function(x) 1/x^2, lower = 1, upper = Inf)$value\narea \n\n[1] 1\n\n\n\nEjemplo de la clase\nPara el ejemplo de la clase, podemos tomar entonces:\n\\[f(x)=\\begin{cases} \\frac{1}{40000}& si  & 10000 \\leq x \\leq 50000 \\\\ 0& si  & ocurre\\; lo\\; contrario\\end{cases}\\]\nCalcular:\n\nLa probabilidad que los empleados consuman en este mes exactamente 30000 litros de gasolina, \\(p(x=30000)\\):\n\nPrimero creamos una función pequeña (esta es la que nos permite) trabajar la integral con la opción de Vectorize.\n\n# Como se trata de una constante hay que vectorizar\nfp &lt;- function(x){1/40000}\nVfp &lt;- Vectorize(fp)\ne1 &lt;- integrate(Vfp, lower = 30000, upper = 30000)$value\ne1\n\n[1] 0\n\n\n\nDe que consuman por lo menos 30000 litros, \\(P (x \\geq 30000)\\):\n\n\ne2 &lt;- 1 - integrate(Vfp, lower = 10000, upper = 30000)$value\ne2\n\n[1] 0.5\n\n\n\nLa probabilidad que consuman entre 20000 y 30000 litros de gasolina, \\(P(20000 \\leq x \\leq 30000)\\):\n\n\ne3 &lt;- integrate(Vfp, lower = 20000, upper = 30000)$value\ne3\n\n[1] 0.25\n\n\nEncontramos cada uno de los valores en R sin requerir de alguna calculadora en particular.\n\n\nOtra manera pero con distribución Uniforme\nCada distribución de probabilidad que maneja R tiene cuatro funciones básicas cuyos nombres consisten en un prefijo seguido del nombre de la distribución. Como ejemplo, miremos la distribución normal. El nombre de las cuatro funciones asociadas a la distribución normal es norm. Los cuatro prefijos son:\n\nd de “densidad” - función de probabilidad / función de densidad de probabilidad\np de “probabilidad” - función de distribución acumulativa\nq de “cuantil” - función de cuantil (función de distribución acumulativa inversa)\nr de “random” - generador de números aleatorios\n\nAsí, para la distribución normal tenemos las funciones de R como: dnorm(), pnorm(), qnorm() y rnorm().\nLa función de R conocida como punif permite extraer los valores de la probabilidad de una distribución uniforme. Recuerde que estas pueden ser:\n\nset.seed(123)\nrunif(n = 30, min = 150, max = 370)\n\n [1] 213.2671 323.4271 239.9749 344.2638 356.9028 160.0224 266.1832 346.3322\n [9] 271.3157 250.4552 360.5033 249.7335 299.0655 275.9793 172.6434 347.9615\n[17] 204.1393 159.2531 222.1426 359.9908 345.6986 302.4167 290.9115 368.7394\n[25] 294.2553 305.8767 269.6945 280.7112 213.6151 182.3650\n\n\nY para graficar con tres (3) escenarios posibles se puede tener:\n\n# Una fila, tres columnas como opción de gráfico\npar(mfrow = c(1, 3))\n\nx &lt;- seq(-0.5, 1.5, 0.01)\n\nset.seed(123)\n\n# n = 10\nhist(runif(10), main = \"n = 100\", xlim = c(-0.2, 1.25),\n     xlab = \"\", prob = TRUE)\nlines(x, dunif(x), col = \"red\", lwd = 2)\n\n# n = 1000\nhist(runif(1000), main = \"n = 10000\", xlim = c(-0.2, 1.25),\n     xlab = \"\", prob = TRUE)\nlines(x, dunif(x), col = \"red\", lwd = 2)\n\n# n = 100000\nhist(runif(100000), main = \"n = 1000000\", xlim = c(-0.2, 1.25),\n     xlab = \"\", prob = TRUE)\nlines(x, dunif(x), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n# Volvemos a una fila y una columna para la opción default de R\npar(mfrow = c(1, 1))\n\nDe vuelta al ejercicio de clase, podemos usar entonces la opción de punif para obtener resultados sin hacer uso de las funciones de interacción:\n\nCaso 1: Exactamente 30 mil litros de gasolina\n\n\n# Lower.tail TRUE es el lado de la probabilidad (x&lt;=)\nh=punif(30000, min=10000, max=50000, lower.tail=T)\nj=punif(30000, min=10000, max=50000, lower.tail=F)\nh-j\n\n[1] 0\n\n\n\nCaso 2: Por lo menos 30000 litros de gasolina\n\n\npunif(30000, min=10000, max=50000, lower.tail=F)\n\n[1] 0.5\n\n\n\nCaso 3: Entre 20000 y 30000\n\n\n# Se usa de la siguiente manera\n# Lower.tail FALSE es el lado de la probabilidad (&gt;)\nh=punif(30000, min=10000, max=50000, lower.tail=F)\nl=punif(20000, min=10000, max=50000, lower.tail=T)\nh-l\n\n[1] 0.25\n\n\nReplicando los resultados anteriormente obtenidos. En resumen hay distintas maneras de llegar a obtener un Resultado de distintas formas posibles.",
    "crumbs": [
      "Parte 1",
      "3: Distribución de datos"
    ]
  },
  {
    "objectID": "lecciones/unidad03.html#subconjuntos-con-filtros",
    "href": "lecciones/unidad03.html#subconjuntos-con-filtros",
    "title": "3: Distribución de datos",
    "section": "Subconjuntos con filtros",
    "text": "Subconjuntos con filtros\nMuchas veces se debe filtrar la base de datos original y convertirla en una base mas pequeña. Para esto, se requiere una condición o característica esencial de interés del investigador.\n\n# Base\ndatos_asuntos\n\n# A tibble: 601 × 19\n      id  male   age yrsmarr  kids relig  educ occup ratemarr naffairs affair\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n 1     4     1    37   10        0     3    18     7        4        0      0\n 2     5     0    27    4        0     4    14     6        4        0      0\n 3     6     1    27    1.5      0     3    18     4        4        3      1\n 4    11     0    32   15        1     1    12     1        4        0      0\n 5    12     0    27    4        1     3    17     1        5        3      1\n 6    16     1    57   15        1     5    18     6        5        0      0\n 7    23     1    22    0.75     0     2    17     6        3        0      0\n 8    29     0    32    1.5      0     2    17     5        5        0      0\n 9    43     1    37   15        1     5    18     6        2        7      1\n10    44     0    22    0.75     0     2    12     1        3        0      0\n# ℹ 591 more rows\n# ℹ 8 more variables: vryhap &lt;dbl&gt;, hapavg &lt;dbl&gt;, avgmarr &lt;dbl&gt;, unhap &lt;dbl&gt;,\n#   vryrel &lt;dbl&gt;, smerel &lt;dbl&gt;, slghtrel &lt;dbl&gt;, notrel &lt;dbl&gt;\n\n# Se hace uso del comando \"Subset\" para seleccionar un subconjunto de una base \n# para aquellas observaciones cuya educación en años es mayor o igual a 10.\nsubset(datos_asuntos, educ&gt;=10)\n\n# A tibble: 594 × 19\n      id  male   age yrsmarr  kids relig  educ occup ratemarr naffairs affair\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n 1     4     1    37   10        0     3    18     7        4        0      0\n 2     5     0    27    4        0     4    14     6        4        0      0\n 3     6     1    27    1.5      0     3    18     4        4        3      1\n 4    11     0    32   15        1     1    12     1        4        0      0\n 5    12     0    27    4        1     3    17     1        5        3      1\n 6    16     1    57   15        1     5    18     6        5        0      0\n 7    23     1    22    0.75     0     2    17     6        3        0      0\n 8    29     0    32    1.5      0     2    17     5        5        0      0\n 9    43     1    37   15        1     5    18     6        2        7      1\n10    44     0    22    0.75     0     2    12     1        3        0      0\n# ℹ 584 more rows\n# ℹ 8 more variables: vryhap &lt;dbl&gt;, hapavg &lt;dbl&gt;, avgmarr &lt;dbl&gt;, unhap &lt;dbl&gt;,\n#   vryrel &lt;dbl&gt;, smerel &lt;dbl&gt;, slghtrel &lt;dbl&gt;, notrel &lt;dbl&gt;\n\n#Se puede adicionar a una nueva base con un nombre nuevo \nmibase&lt;- subset(datos_asuntos, educ&gt;=10)\n#Mirar en formato tradicional   \nView(mibase)\n#Un subset con variable cualitativa (tipo filtro) cuando la pareja \n#'si' tiene hijos\nsubset(datos_asuntos, kids==1)\n\n# A tibble: 430 × 19\n      id  male   age yrsmarr  kids relig  educ occup ratemarr naffairs affair\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n 1    11     0    32      15     1     1    12     1        4        0      0\n 2    12     0    27       4     1     3    17     1        5        3      1\n 3    16     1    57      15     1     5    18     6        5        0      0\n 4    43     1    37      15     1     5    18     6        2        7      1\n 5    45     1    57      15     1     2    14     4        4        0      0\n 6    47     0    32      15     1     4    16     1        2        0      0\n 7    50     1    37      15     1     2    20     7        2        0      0\n 8    53     0    32      10     1     3    17     5        2       12      1\n 9    55     1    27       4     1     4    18     6        4        0      0\n10    64     1    47      15     1     5    17     6        4        0      0\n# ℹ 420 more rows\n# ℹ 8 more variables: vryhap &lt;dbl&gt;, hapavg &lt;dbl&gt;, avgmarr &lt;dbl&gt;, unhap &lt;dbl&gt;,\n#   vryrel &lt;dbl&gt;, smerel &lt;dbl&gt;, slghtrel &lt;dbl&gt;, notrel &lt;dbl&gt;",
    "crumbs": [
      "Parte 1",
      "3: Distribución de datos"
    ]
  },
  {
    "objectID": "lecciones/unidad03.html#correlación-entre-una-variable-categorica-y-una-continua",
    "href": "lecciones/unidad03.html#correlación-entre-una-variable-categorica-y-una-continua",
    "title": "3: Distribución de datos",
    "section": "Correlación entre una variable categorica y una continua",
    "text": "Correlación entre una variable categorica y una continua\nEn algunas ocasiones podemos mirar, si una característica incide sobre la correlación de alguna variable. Digamos que queremos mirar si haber tomado café/tinto incide en algo o tiene relación en el rendimiento de una persona en un examen de calificación. Tome en consideración lo siguiente:\n\ntinto&lt;-c(1,1,0,0,0,1,1,1,1,1)\nnotas_Econ&lt;-c(4.3,3.7,2.3,2.2,2.1,4.41,4.46,3.72,3.33,3.50)\n\n# Calculamos la correlación Bi-serial\n\ncor.test(tinto, notas_Econ)\n\n\n    Pearson's product-moment correlation\n\ndata:  tinto and notas_Econ\nt = 6.1518, df = 8, p-value = 0.0002735\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6518232 0.9784589\nsample estimates:\n      cor \n0.9085684 \n\n\nLo que nos arroja un resultado de 0.90 de correlación que interpretamos como una correlación alta cuando tomamos café y enfrentamos una prueba. Cuando esa persona tomó café tuvo mejores resultados que cuando no lo hizo -Recuerde que son correlaciones y implica causalidad-",
    "crumbs": [
      "Parte 1",
      "3: Distribución de datos"
    ]
  },
  {
    "objectID": "lecciones/unidad03.html#zonas-de-rechazo-de-hipótesis",
    "href": "lecciones/unidad03.html#zonas-de-rechazo-de-hipótesis",
    "title": "3: Distribución de datos",
    "section": "Zonas de rechazo de hipótesis",
    "text": "Zonas de rechazo de hipótesis\nMuchas veces para los contrastes estadísticos tendremos que usar el \\((\\alpha)\\) o error de confianza para rechazar o no hipótesis nulas \\((H_{0})\\). El código para obtenerlo en R siempre tiene sus cosas, lo recomendable es que escriba el código totalmente y luego si ejecute seleccionando todo con la opción de ctrl+enter:\n\nx&lt;-seq(-5,5,0.1) #Creamos los datos (estos son aleatorios)\nhist &lt;- dnorm(x, mean=0, sd=1) #Guardamos el histograma\n#Toda esta parte a continuación debe correrla de un solo ``tajo'':\nplot(x, hist, type=\"l\", xlab=\"Desviación estándar\", ylab=\"Densidad de probabilidad\",main=\"Grafico de Densidad\",\nlty = 1, lwd = 2, yaxs=\"i\") # yaxs=\"i\" significa el límite del dato en el eje\npolygon(c(x[x &gt;= 1.96], 2), c(dnorm(x[x &gt;= 1.96]), 0), col=\"gray\")\npolygon(c(x[x &lt;=-1.96], -2), c(dnorm(x[x &lt;= -1.96]), 0), col=\"gray\")\ntext(0, .1,\"0.95\")\ntext(-3, .05,expression(alpha==0.025), col = \"red\")\ntext(3, .05,expression(alpha==0.025), col = \"red\")\n\n\n\n\n\n\n\n\nEl análisis de \\((\\alpha)\\) hace referencia a los niveles específicos de los niveles de confianza de una prueba cualquiera, por ejemplo: recuerde cuando se tienen dos eventos, uno es verdadero con probabilidad (P) y otro falso con probabilidad (1-P), ambos son excluyentes y le piden que demuestre el resultado que se de uno de ellos. Para el caso de las Pruebas de hipótesis es lo mismo, una parte que es cierta o verdadera y la otra que es falsa. En econometría y estadística siempre se usa de tal forma que \\((1-\\alpha)\\) o (1-P) es la parte1 de \\(95\\%\\) - siendo el nivel estándar de las pruebas científicas - y su contraste es \\(\\alpha\\) o es 5%. En otros casos - mas exigentes-, puede llegar a ser \\((1-\\alpha)=99\\%\\) y por ende \\(\\alpha\\) será igual a \\(1\\%\\).\nEn el análisis de datos, al igual que en la econometría y en muchas partes, se debe siempre  testear  o probar los resultados en el universo estadístico que brindan las distribuciones.\nTomemos por ejemplo una distribución -recuerde que necesitamos de estas porque se convierten en el mapa a aproximar cuando realizamos estimaciones muestrales-.\n\n# Generar datos\nset.seed(5672) #Una semilla de replicación para que a todos nos salga lo mismo\nrnorm(100)\n\n  [1] -0.18400862 -1.05931512  1.50759363 -0.60075771  0.79107108 -0.44334303\n  [7] -0.35042110 -1.25450334  0.63799236  0.64631285 -0.14895577 -0.87483080\n [13] -0.15824114  0.56376500 -1.34740602  0.91685198  2.26423302 -0.70910236\n [19] -0.82977862 -0.89983410  1.37276199  0.85239574  0.49860312 -1.17692668\n [25]  0.75194573 -0.08792311  0.65682396  1.52469404  0.71705327 -1.37207571\n [31] -0.97292872  1.78510555 -1.31422047  3.06131557  0.19678032  0.78088015\n [37]  0.75275186  1.61846625 -1.75956334 -0.05631070 -1.14023988  0.66007969\n [43] -0.71299941  1.23366144 -0.25807622 -1.43845021 -1.36962926 -0.40745676\n [49]  0.49351508 -0.61838224  1.10034077  2.33600094  1.30356426 -0.88262713\n [55]  0.92618206  1.40416805 -1.20909561  0.25622506 -0.46374507  1.51006044\n [61] -0.58142586 -0.98291735  1.99639339 -0.89036509  0.04713117 -0.16852734\n [67] -0.62740703 -1.25127174 -2.00665347 -0.11183343  0.66415330 -1.29488126\n [73]  0.68489035  0.99119783  0.69521727  0.09763780  1.74954562 -1.82436693\n [79] -1.55433115 -0.02273659 -1.11844353  2.42255285 -1.73167894 -1.53284360\n [85] -0.24999095 -2.02380378  0.29885479  1.54184598  0.13739446 -0.67621809\n [91] -0.55691948 -0.45189730 -1.01214765  0.80377864 -0.17124248  0.41844004\n [97]  0.70987117  0.29105856 -1.09294074  0.14208391\n\n#Asignar a un vector\ny&lt;-rnorm(100)\n# Figura de histograma\nhist(y, main=\"Un histograma de la Dist. normal\", ylab = \"Frecuencia de datos\")\n\n\n\n\n\n\n\n\nLa forma en como se distribuyen los datos nos podrán “mapear” como lo hace un universo de observaciones que quizás no logremos tener (por el alto costo de conseguir esa información o porque no exista suficiente espacio o memoria en nuestro ordenador), sin embargo, a partir de eso podremos inferir lo que ocurre generalmente con las cosas.\nHay datos que se distribuyen normal porque su naturaleza  es independiente y aleatoria, es por esto que se comportan de forma “Normal” o se distribuyen así. Por otro lado, podemos encontrar datos que se distribuyen de otra manera, es el caso de la distribución discreta de la binomial, como se muestra a continuación:\n\n# Una gráfica para la distribución binomial\n# Valores de x: Números del o al 10 con una secuencia\nx &lt;- seq(0,10)\n\n# Función para todos esos valores\nfx &lt;- dbinom(x, 10, 0.2)\n\n# Tabla de (matriz) de valores\ncbind(x, fx) \n\n       x           fx\n [1,]  0 0.1073741824\n [2,]  1 0.2684354560\n [3,]  2 0.3019898880\n [4,]  3 0.2013265920\n [5,]  4 0.0880803840\n [6,]  5 0.0264241152\n [7,]  6 0.0055050240\n [8,]  7 0.0007864320\n [9,]  8 0.0000737280\n[10,]  9 0.0000040960\n[11,] 10 0.0000001024\n\n# Gráfico con distintas formas de las lineas\nplot(x, fx, type=\"h\")\n\n\n\n\n\n\n\nplot(x, fx, type = \"c\")\n\n\n\n\n\n\n\nplot(x, fx, type = \"l\")\n\n\n\n\n\n\n\n\nSaber de las distribuciones nos permite resolver  problemas  como los que se presentan a continuación: Sea \\(X\\) un conjunto de balotas de color verde que se pueden extraer de una bolsa que regularmente solo contiene un 15% de ese color. Con los siguientes parámetros: n=20 total de pelotas dentro de la bolsa y \\(p=15\\%=0.15\\). Si queremos conocer la probabilidad de sacar 3 pelotas de color  verde , debemos entonces hacer uso de una distribución. Todos sabemos que la probabilidad va en \\(x \\in \\{0,1,2,\\dots,20\\}\\), la propuesta de desarrollo es:\n\\[f(x)=P(X=x) = \\binom{n}{x} \\cdot P^{x} \\cdot (1-P)^{n-x}= \\binom{20}{x} \\cdot 0.15 \\cdot (0.85)^{20-x}\\] La pregunta va en dirección de la probabilidad de sacar 3 balotas de color  verde , lo que es:\n\\[f(x)= \\binom{20}{3} \\cdot 0.15 \\cdot (0.85)^{20-3}\\] En el Software R es muy fácil aplicar el comando dbinom(x,n,p) y tendremos:\n\ndbinom(3,20,0.15)\n\n[1] 0.2428289\n\n\nDándonos como resultado una probabilidad de 24.28% de sacar tres (3) pelotas de color  verde  en dicho experimento.",
    "crumbs": [
      "Parte 1",
      "3: Distribución de datos"
    ]
  },
  {
    "objectID": "lecciones/unidad03.html#de-la-función-de-distribución-acumulada-fda",
    "href": "lecciones/unidad03.html#de-la-función-de-distribución-acumulada-fda",
    "title": "3: Distribución de datos",
    "section": "De la función de distribución acumulada (FDA)",
    "text": "De la función de distribución acumulada (FDA)\nLa FDA es aquella que representa la probabilidad de que X tome al menos el valor de (x). Tenga presente lo siguiente:\n\\[F(x)= P(X \\leq x)\\] X puede tomar distintos valores muestrales. Suponga que X es el salario de una persona, la parte (x) puede ser 50000 o 100000 y así cualquier otro valor. Si queremos mirar por ejemplo, cual es la probabilidad de que X este entre a y b?, ya hacemos uso por ejemplo de \\(P(a\\leq X \\leq b)\\).\nMire que si sabemos que \\(X \\sim (10, 24)\\). podemos entonces preguntarnos: ¿Cuál es la probabilidad que X este (o tome valores) entre 6 y 12. Una respuesta para eso es\n\\[\\mu_{x}= \\frac{6-10}{4.9}=\\Phi \\left( \\frac{-4}{5} \\right)\\] De forma similar es para el otro valor\n\\[\\mu_{x}= \\frac{12-10}{4.9}=\\Phi \\left(\\frac{2}{5} \\right)\\] En R es sencillo entonces tener:\n\n# De forma normal\npnorm(2/5)-pnorm(-4/5)\n\n[1] 0.4435663\n\n# Luego de forma directa\npnorm(12,10,5)-pnorm(6,10,5)\n\n[1] 0.4435663\n\n\nY obtenemos el mismo resultado de acuerdo a lo que estemos hallando. La probabilidad en este casi es del 44.35%.\n\nGrafica de la FDA\nTanto los sucesos de una distribución binomial o normal siguen una distribución de la siguiente manera:\n\nset.seed(123)\nx&lt;-seq(-2,15)\nFx&lt;-pbinom(x, 15, 0.2)\npar(mfrow = c(1, 2))\nplot(x, Fx, type=\"s\")\ncurve(pnorm(x), -5,5)\n\n\n\n\n\n\n\n\nEl universo del comportamiento de las variables, nos permiten hacer inferencia de todo tipo.",
    "crumbs": [
      "Parte 1",
      "3: Distribución de datos"
    ]
  },
  {
    "objectID": "lecciones/unidad03.html#footnotes",
    "href": "lecciones/unidad03.html#footnotes",
    "title": "3: Distribución de datos",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEste criterio siempre va a depender del investigador y de los recursos con que cuenta.↩︎",
    "crumbs": [
      "Parte 1",
      "3: Distribución de datos"
    ]
  },
  {
    "objectID": "lecciones/unidad04.html#valores-críticos",
    "href": "lecciones/unidad04.html#valores-críticos",
    "title": "4: Mínimos Cuadrados Ordinarios",
    "section": "Valores críticos",
    "text": "Valores críticos\nDe la existencia de los valores críticos podremos tener nuestras zonas de rechazo de hipótesis. Con estos podemos con suficiente evidencia probar una pregunta de investigación. Para establecerlos, debemos dar por sentada la  significancia  o nivel de la prueba, a mayor nivel la zona “critica” será aún mas exigente para testear algo -cosa que siempre debemos desear1-. En la medida que su confianza exija un mayor nivel esta asumiendo pruebas con una población mas grande. Los niveles van en el 90% muestras pequeñas y menor es la exigencia (zona critica muy “relajada”), mientras que en un 95% es mucho mas completa y exigente, ya para el caso superior se debe tomar el nivel de 99%. En  R  es fácil obtenerlo a partir del comando qnorm()\n\n# Buscar en las tabla de la normal en niveles de significancia\nqnorm(0.90)\n\n[1] 1.281552\n\n\nRecuerde que esto es como tener un espacio límite de valores (en la guía anterior ya se había hecho una explicación al respecto de esto)\n\n\n\n\n\n\n\n\n\nSi quiere ser un poco mas estricto puede usar niveles de confianza superiores que reducirán de forma consistente el area de rechazo de la prueba de hipotesis. Mire la siguiente tabla:\n\n\n\nFunciones\nValores críticos\nPonderación\n\n\n\n\nqnorm(0.95)\n1.64\nAlta\n\n\nqnorm(0.975)\n1.96\nMuy Alta\n\n\nqnorm(0.99)\n2.33\nEstricta\n\n\n\nSi nota, la zona de rechazo se hace mas pequeña debido al nivel de confianza. Es de esperar que usted siempre este evaluando al máximo nivel posible.\nEn lo consecuente para la tabla de distribuciones que requieran a la table T-Student, la opción a usar es qt(p,n) donde \\(p\\) es el nivel de confianza y \\(n\\) viene a ser el tamaño de la muestra o número de observaciones:\n\nqt(0.95, 30)\n\n[1] 1.697261\n\n\nEsos límites calculados o hallados serán denominados como nuestros estadísticos críticos, con el objeto de rechazar nuestras hipótesis nulas, el T-Calculado debe ser mayor en su valor absoluto a estos valores críticos. A diferencia de qnorm debe añadirse \\((n)\\) que es el tamaño de la muestra y no el de la población.",
    "crumbs": [
      "Parte 1",
      "4: Mínimos Cuadrados Ordinarios"
    ]
  },
  {
    "objectID": "lecciones/unidad04.html#intervalos-de-confianza",
    "href": "lecciones/unidad04.html#intervalos-de-confianza",
    "title": "4: Mínimos Cuadrados Ordinarios",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\nEntendiendo mejor los valores críticos, podemos entonces construir intervalos de confianza que permitirán inferir donde se ubica o esta el promedio de una variable.\n\\[\\left[ \\bar{y} - \\text{Valor crítico} \\frac{\\alpha}{2} \\times s.e(\\bar{y}) \\leq \\bar{y} \\leq \\bar{y} + \\text{Valor crítico} \\frac{\\alpha}{2} \\times s.e(\\bar{y}) \\right]\\]\nLa clave es el valor crítico, quien viene a ser nuestro límite de zona, debe usted estar en capacidad de mirar que las pruebas estadísticas así lo requieren. Miremos que el valor crítico es el que nos da el nivel del 95% con muestras grandes, entonces usemos el que nos da el qnorm(95)\n\\[\\left[ \\bar{y} - 1.65  \\times s.e(\\bar{y}) \\leq \\bar{y} \\leq \\bar{y} + 1.65 \\times s.e(\\bar{y}) \\right]\\] El resto de valores son la media (promedio) de la variable a evaluar y su respectiva desviación estándar (s.e).\n\nAplicación\n\nTomemos por ejemplo el numero de firmas o empresas que se capacitaron laboralmente dentro un periodo de tiempo. Queremos mostrar si hay o existe alguna diferencia entre el grupo que recibe la capacitación o entrenamiento y de otro que no lo hizo2. Diremos que los tratados hacen referencia a los que se trataron o fueron seleccionados para el proceso de entrenamiento/capacitación y los controles como aquellos que no lo fueron o no tomaron esa capacitación.\nPrimero vamos a definir un estadístico de prueba o que mida el cambio. Esto significa que vamos a mirar la  diferencia  de los promedios de aquellos individuos/firmas que tuvieron la capacitación versus aquellos que no la tuvieron. Para eso vamos a utilizar el estadístico de \\(\\tau_i\\) que significa:\n\\[\\tau_i= \\text{Promedio de los Tratados}-\\text{Promedio de los Controles}\\] Esto es como mirar lo que se conoce como  Diferencia de medias(promedios) \n\n# Datos de ejemplo\ntratados&lt;-c(10,1,6,.45,1.25,1.3,1.06,3,8.18,1.67,.98,1,.45,5.03,8,9,18,.28,\n        7,3.97)\ncontroles&lt;-c(3,1,5,.5,1.54,1.5,.8,2,.67,1.17,.51,.5,.61,6.7,4,7,19,.2,5,3.83)\n# Creamos nuestro estadístico de prueba\nCambio &lt;- tratados - controles\n# Ingredientes para el intervalo y su formula: usamos parentesis para resultados\navgCh&lt;- mean(Cambio)\nn    &lt;- length(Cambio)\nsdCh &lt;- sd(Cambio)\nse   &lt;- sdCh/sqrt(n)\nc    &lt;- qt(.975, n-1)\n# Intervalo de confianza al 97.5%:\nc(avgCh - c*se, avgCh + c*se)\n\n[1] 0.03096631 2.27803369\n\n\nEsto no es mas que la aplicación de la formula que se explicó anteriormente para el intervalo de confianza de \\((\\bar{y})\\) solo que estamos usando en esta ocasión la diferencia de promedios o \\((\\tau)\\):\n\\[\\left[0.030\\leq \\tau_i\\leq 2.28\\right]\\]\nQue es el intervalo de nuestra prueba y mirando que nuestro estadístico o media “cae” dentro del intervalo. Podríamos estar pensando en rechazar posiblemente nuestra hipotesis nula o \\(H_0\\). Sin embargo, interpretemos todo y lo anterior hacerlo en un solo paso o forma con el comando t.test:\n\n# Ejemplo de dos colas: Intervalo de confianza\nt.test(Cambio)\n\n\n    One Sample t-test\n\ndata:  Cambio\nt = 2.1507, df = 19, p-value = 0.04458\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.03096631 2.27803369\nsample estimates:\nmean of x \n   1.1545 \n\n\nPara el caso, encontramos que si existen diferencias entre un grupo y el otro con respecto a la capacitación por lo menos con 95% de significancia. Lo que nos indica que la capacitación si ha tenido impacto y que deberían aplicarse a futuro otras capacitaciones. El t=2.15 es el calculado y si vemos, es mayor al t-critico t=1.69 que es el valor que sale en la tabla de la t-student. La parte de df viene a ser la parte de los grados de libertad de los datos. Note que el p-value es la probabilidad de caer en la zona de no rechazo y por ende es el argumento que nos lleva a decir la razón de rechazar \\(H_0\\).\n\nOtras opciones\nAdemas de lo anterior, también podemos hacer pruebas de una cola respectivamente. Suponga que por un momento se dice que la capacitación ha tenido efectos negativos en el rendimiento de un grupo con respecto al otro.\n\\[\\begin{aligned}\nH_0: & \\tau_i = 0 \\\\\nH_a: & \\tau_i \\leq 0\n\\end{aligned}\\]\n\n# Cuando es solo evaluar la parte izquierda\nt.test(Cambio, alternative=\"less\") \n\n\n    One Sample t-test\n\ndata:  Cambio\nt = 2.1507, df = 19, p-value = 0.9777\nalternative hypothesis: true mean is less than 0\n95 percent confidence interval:\n     -Inf 2.082697\nsample estimates:\nmean of x \n   1.1545 \n\n\nTeniendo como resultado no rechazar la hipotesis nula. En este caso el rendimiento no ha justificado que los trabajadores con el curso hayan salido peor de lo que iniciaron.\nPara mirar, sea el caso que el grupo capacitado tenga un mejor rendimiento que otro desde (0) como escala o criterio, podemos hacer lo siguiente:\n\\[\\begin{aligned}\nH_0: & \\tau_i = 0 \\\\\nH_a: & \\tau_i \\geq 0\n\\end{aligned}\\]\n\n# Cuando solo quiere evaluar los mayores o parte derecha\nt.test(Cambio, alternative=\"greater\") \n\n\n    One Sample t-test\n\ndata:  Cambio\nt = 2.1507, df = 19, p-value = 0.02229\nalternative hypothesis: true mean is greater than 0\n95 percent confidence interval:\n 0.2263028       Inf\nsample estimates:\nmean of x \n   1.1545 \n\n\nEn esta ocasión si podemos rechazar la hipótesis nula de que no existe diferencias entre grupo de capacitados y los que no lo hicieron. Desde luego el programa de capacitación mejora significativamente el rendimiento de un grupo versus el otro.\nLa parte que usó less es aquello que miden \\(H_1: \\tau \\leq \\tau_{0}\\) y la parte correspondiente a greater es \\(H_1: \\tau \\geq \\tau_{0}\\).",
    "crumbs": [
      "Parte 1",
      "4: Mínimos Cuadrados Ordinarios"
    ]
  },
  {
    "objectID": "lecciones/unidad04.html#ingredientes-del-modelo",
    "href": "lecciones/unidad04.html#ingredientes-del-modelo",
    "title": "4: Mínimos Cuadrados Ordinarios",
    "section": "Ingredientes del modelo",
    "text": "Ingredientes del modelo\nPara tener nuestro modelo, entonces debemos implementar un par de métricas que nos iran dando los ingredientes que requerimos para el cálculo de la mejor linea de ajuste.\n\nCovarianza\nPara este solo podemos hacer lo siguiente:\n\ncov(exper, wage) \n\n[1] 3.873389\n\n\nEsta no tiene ninguna interpretación pero por lo menos su signo, si nos va dando dirección de la relación que tiene la variable objetivo del salario con la experiencia del individuo.\n\n\nVarianza\nLa varianza de la variable explicativa nos permite entonces encontrar el peso o estimador adecuado.\n\nvar(exper)\n\n[1] 19.13701\n\n\n\n\nMedia de la variable dependiente e independiente\nLos promedios de cada una de las variables que estaremos usando en nuestro modelo, nos permite entonces tener la característica de cada una en este caso.\n\nmean(wage)\n\n[1] 957.9455\n\nmean(exper)\n\n[1] 11.56364",
    "crumbs": [
      "Parte 1",
      "4: Mínimos Cuadrados Ordinarios"
    ]
  },
  {
    "objectID": "lecciones/unidad04.html#test-de-normalidad",
    "href": "lecciones/unidad04.html#test-de-normalidad",
    "title": "4: Mínimos Cuadrados Ordinarios",
    "section": "Test de Normalidad",
    "text": "Test de Normalidad\nLa prueba de hipótesis de la distribución normal de los residuos puede escribirse plantearse así:\n\\[\\begin{aligned}\n    H_{0}:&\\; \\text{Se distribuye,}\\; \\mu \\sim N \\left (0, \\sigma^2  \\right )\\\\\n    H_{a}:& \\; \\text{No se distribuye,}\\; \\mu \\sim N \\left (0, \\sigma^2  \\right )\n\\end{aligned}\\]\nMiremos una gráfica de los residuos del modelo anterior:\n\n#Normalidad de los residuos (importante)\nhist(u.hat, main = \"Histograma de los residuos\")\n\n\n\n\n\n\n\n\nAl parecer los residuos de nuestro modelo no presentan un comportamiento adecuado o similar a la campana de Gauss, mas bien tiene algo de sesgo positivo y podriamos pensar que no sigue una distribución  normal  .\nLa formula para obtener el estadístico de Jarque- Bera es:\n\\[JB=\\left [ \\frac{s^2}{6} \\times \\frac{(k-3)^2}{24} \\right ]\\sim \\chi^2\\] Donde \\(s\\) es la asimetría, \\(k\\) es la curtosis y se distribuye chi-cuadrado. De la prueba podemos hacerla con el paquete moments y de ahi mirar si los residuos sigan una distribución normal.\n\nlibrary(moments) # Paquete estadistico\njarque.test(u.hat)\n\n\n    Jarque-Bera Normality Test\n\ndata:  u.hat\nJB = 507.99, p-value &lt; 2.2e-16\nalternative hypothesis: greater\n\n\nEl resultado anterior nos muestra lo que sospechábamos. El estadistico permite rechazar la hipótesis de normalidad ya que este \\(507.99&gt; \\; \\text{Chí-critico}\\) y el p valor es casi cero, por ende no es normal.\nDe las propiedades mas importantes, destacamos que nuestro modelo las satisface en su gran mayoría. La normalidad de los residuos es importante tenerla, ya que nos permite decir si los \\(\\beta `s\\) son consistentes y eficientes, sin embargo, podemos asumir la insesgadez y linealidad de estos parámetros encontrados.",
    "crumbs": [
      "Parte 1",
      "4: Mínimos Cuadrados Ordinarios"
    ]
  },
  {
    "objectID": "lecciones/unidad04.html#footnotes",
    "href": "lecciones/unidad04.html#footnotes",
    "title": "4: Mínimos Cuadrados Ordinarios",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImaginese que usted siempre quiere competir y comparse con los mejores. Uno siempre desea para mirar con quien ser mas competivo(a) y por ende el nivel debe ser aun mas alto o mas estricto.↩︎\nPersonas, instituciones o firmas que tomamos como controles de la prueba y que no fueron seleccionada(o)s para aprender/capacitarse/entrenarse. Recuerde que aprender cierta técnica sugiere que un grupo sea mas productivo o mejor que aquellos que no hayan realizado el curso/capacitación/entrenamiento.↩︎",
    "crumbs": [
      "Parte 1",
      "4: Mínimos Cuadrados Ordinarios"
    ]
  },
  {
    "objectID": "lecciones/unidad05.html#de-la-elasticidad",
    "href": "lecciones/unidad05.html#de-la-elasticidad",
    "title": "5: Formas Funcionales de MCO",
    "section": "De la elasticidad",
    "text": "De la elasticidad\nDentro del análisis econométrico, sobre sale también el económico, podemos usar una medida de sensibilidad de las variables, este es simple y se denomina  elasticidad . Considere siempre que la identificación es:\n\\[Elasticidad=\\left\\{\\begin{matrix}\n|\\epsilon| &gt; & 1 \\quad \\text{Elástica} \\\\\n|\\epsilon| &lt; & 1 \\quad \\text{Inelástica} \\\\\n|\\epsilon| = & 1 \\quad \\text{Unitaria} \\\\\n\\end{matrix}\\right.\\]\nHay que tener presente la ecuación de la elasticidad es:\n\\[\\epsilon= \\frac{\\delta Y/Y}{\\delta X/X} = \\frac{\\delta Y}{\\delta X} \\times \\frac{X}{Y}\\]\nEn el caso del modelo de regresión, estimar el \\(\\beta_{i}\\) resulta ser la medida del cambio de \\(Y\\) brindado por \\(X\\). Lo que resulta ser: \\[\\epsilon= \\widehat{\\beta}_{i} \\times \\frac{X}{Y}\\]\nPara una simplificación mayor tomaremos los valores promedios de cada una de las variables explicativas y dependiente y con esto se obtendrá la elasticidad promedio.\n\n#Para elasticidad\nattach(datos)\n(b1hat &lt;- cov(exper,wage)/var(exper)) #Hallar beta de reg\n\n[1] 0.2024031\n\nelasticidad&lt;-b1hat*(exper/sal.hat)\n\n## Distintas formas ##\nmelasticidad&lt;-b1hat*(mean(exper)/mean(wage))  #Forma 1\nmelasticidad2&lt;-b1hat*(mean(exper)/mean(sal.hat)) #Forma 2\n\n## Tabla de salida\ncbind(wage, exper, elasticidad, melasticidad, melasticidad2 )[1:10,]\n\n   wage exper elasticidad melasticidad melasticidad2\n1   769    11 0.002324453  0.002443266   0.002443266\n2   808    11 0.002324453  0.002443266   0.002443266\n3   825    11 0.002324453  0.002443266   0.002443266\n4   650    13 0.002745920  0.002443266   0.002443266\n5   562    14 0.002956520  0.002443266   0.002443266\n6  1400    14 0.002956520  0.002443266   0.002443266\n7   600    13 0.002745920  0.002443266   0.002443266\n8  1081     8 0.001691584  0.002443266   0.002443266\n9  1154    13 0.002745920  0.002443266   0.002443266\n10 1000    16 0.003377454  0.002443266   0.002443266\n\ndetach(datos)\n\nPara este caso la elasticidad punto o individual de cada una de las observaciones es un tinte inelástica, lo que apoya a decir que un cambio en un uno (1) por-ciento % genera un cambio en el salario de 0.2 por-ciento.",
    "crumbs": [
      "Parte 1",
      "5: Formas Funcionales de MCO"
    ]
  },
  {
    "objectID": "lecciones/unidad05.html#regresión-sin-constante-con-constante-y-con-constante-e-intercepto",
    "href": "lecciones/unidad05.html#regresión-sin-constante-con-constante-y-con-constante-e-intercepto",
    "title": "5: Formas Funcionales de MCO",
    "section": "Regresión sin constante, con constante y con constante e intercepto",
    "text": "Regresión sin constante, con constante y con constante e intercepto\nAlgunas veces, se hace necesario -solo si la teoría así lo indica- de estimar una regresión a través del origen o sin constante o intercepto. Las opciones para este tipo de estimaciones son:\n\n#Regresion sin constante, con constante y solo constante\n# La regresión normal\n(reg1 &lt;- lm(wage ~ exper, data=datos))\n\n\nCall:\nlm(formula = wage ~ exper, data = datos)\n\nCoefficients:\n(Intercept)        exper  \n   955.6049       0.2024  \n\n# Regresión sin intercepto (a través del origen):\n(reg2 &lt;- lm(wage ~ 0 + exper, data=datos))\n\n\nCall:\nlm(formula = wage ~ 0 + exper, data = datos)\n\nCoefficients:\nexper  \n 72.5  \n\n# Regresión sin pendiente con solo la constante:\n(reg3 &lt;- lm(wage ~ 1 , data=datos))\n\n\nCall:\nlm(formula = wage ~ 1, data = datos)\n\nCoefficients:\n(Intercept)  \n      957.9  \n\n# Es el mismo promedio\nmean(datos$wage)\n\n[1] 957.9455\n\n\nUn resumen de los resultados de cada modelo ahora estimado:\n\nreg1 &lt;- lm(wage ~ exper, data=datos)\nreg2 &lt;- lm(wage ~ 0 + exper, data=datos)\nreg3 &lt;- lm(wage ~ 1 , data=datos)\n\n# Todo el grupo de regresiones\nregfh &lt;- list(\"Modelo Lineal\" = reg1, \"Modelo sin constante\" = reg2, \n             \"Modelo sin explicativa\" = reg3)\n\nhuxreg(regfh, statistics = c(N = \"nobs\", R2 = \"r.squared\"),\n       note = \"Nota: Son transformaciones simples\")\n\n\n\nModelo LinealModelo sin constanteModelo sin explicativa\n\n(Intercept)955.605 ***        957.945 ***\n\n(37.411)           (13.224)   \n\nexper0.202    72.505 ***        \n\n(3.026)   (1.394)           \n\nN935        935        935        \n\nR20.000    0.743    0.000    \n\nNota: Son transformaciones simples\n\n\n\n\nA continuación el grupo de lineas que implican esto:\n\n# Gráfico de las 3 regresiones\nplot(datos$exper, datos$wage, xlab = \"Experiencia en años\", ylab = \"Salario en millones\")\nabline(reg1, lwd=2, lty=1)\nabline(reg2, lwd=2, lty=2)\nabline(reg3, lwd=2, lty=3)\nlegend(\"topleft\",c(\"Completo\",\"A traves del origen\",\"Solo la constante\"),lwd=2,lty=1:3)",
    "crumbs": [
      "Parte 1",
      "5: Formas Funcionales de MCO"
    ]
  },
  {
    "objectID": "lecciones/unidad06.html#otra-forma-de-hacerlo-pero-con-rbind",
    "href": "lecciones/unidad06.html#otra-forma-de-hacerlo-pero-con-rbind",
    "title": "6: Matrices y regresión múltiple",
    "section": "Otra forma de hacerlo pero con rbind:",
    "text": "Otra forma de hacerlo pero con rbind:\nSi quizas quiere o desea otro formato para escribir las matrices en  R , viene siendo usando la opción de rbind. Este suma cada vector en forma de filas.\n\nfila1 &lt;- c(3.2,2.5,2.4); fila2 &lt;- c(3.3,3.1,3.3)\n( A &lt;- rbind(fila1, fila2) ) \n\n      [,1] [,2] [,3]\nfila1  3.2  2.5  2.4\nfila2  3.3  3.1  3.3",
    "crumbs": [
      "Parte 1",
      "6: Matrices y regresión múltiple"
    ]
  },
  {
    "objectID": "lecciones/unidad06.html#se-puede-hacer-tambien-por-columnas-cbind",
    "href": "lecciones/unidad06.html#se-puede-hacer-tambien-por-columnas-cbind",
    "title": "6: Matrices y regresión múltiple",
    "section": "Se puede hacer tambien por columnas (cbind)",
    "text": "Se puede hacer tambien por columnas (cbind)\nDesde luego las opciones son varias para escribir matrices. Otra manera de hacerlo es con lo siguiente:\n\ncol1 &lt;- c(3.2,3.3); col2 &lt;- c(2.5,3.1); col3 &lt;- c(2.4,3.3)\n( A &lt;- cbind(col1, col2, col3) )\n\n     col1 col2 col3\n[1,]  3.2  2.5  2.4\n[2,]  3.3  3.1  3.3\n\n\nPensemos que le queremos dar estructura a una matriz. Digamos que tenemos dos estudiantes de Economía y han matriculado un grupo de materias como las siguientes y desde luego han obtenido las siguientes notas.\n\n# Se le puede dar nombres para mejorar formato\ncolnames(A) &lt;- c(\"Micro I\",\"Macro II\",\" Econometría I\")\nrownames(A) &lt;- c(\"Ozuna\",\"Karol G\") \nA\n\n        Micro I Macro II  Econometría I\nOzuna       3.2      2.5            2.4\nKarol G     3.3      3.1            3.3\n\n\nY de esta forma tendrá algo mas estructurado. Recuerde ademas que las matrices tienen distintas formas y con ellas podemos hacer o tener distintos cálculos.\n\n# Matriz Diagonal y matrices de identidad: \ndiag( c(15,-2,21) )\n\n     [,1] [,2] [,3]\n[1,]   15    0    0\n[2,]    0   -2    0\n[3,]    0    0   21\n\ndiag(3)\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n\n# Forma de los elementos dentro de las matrices: Primer elemento es fila\n#Segundo elemento es columna\nA[2,1] # Sale el elemento de la Fila 2 y columna 1\n\n[1] 3.3\n\nA[,2]\n\n  Ozuna Karol G \n    2.5     3.1 \n\nA[,c(1,3)] #Correspondiente  Micro I y Econometria I\n\n        Micro I  Econometría I\nOzuna       3.2            2.4\nKarol G     3.3            3.3\n\n\nCon las matrices también se pueden hacer distintas operaciones básicas de calculo como adición, sustracción o restas, divisiones, multiplicaciones, siempre es bueno tener en mente las propiedades y leyes de orden para poder realizar este tipo de operación. Las sumas y restas deben operarse desde el mismo tamaño matricial. Lo que es, si la matriz A es de tamaño \\(n\\times k\\) entonces la matriz B también debe tener el mismo tamaño. Ejemplo:\n\\[A= \\begin{pmatrix}\n1 &2 \\\\\n3&4\n\\end{pmatrix}\nB=\n\\begin{pmatrix}\n5 &6 \\\\\n7&8\n\\end{pmatrix}\\]\nEsto es, si se tiene \\(A+B\\), el resultado es:\n\\[A+B=\\begin{pmatrix}\n6 &8 \\\\\n10&12\n\\end{pmatrix}\\]\nIncluso esto aplica a operaciones de multiplicación cuando se trata de elemento a elemento.\n\\[\nC= \\begin{pmatrix}\n8 &-4  &6 \\\\\n2 & 7 & 0\n\\end{pmatrix}_{2*3} \\quad y \\quad\nD= \\begin{pmatrix}\n4 &2  &-1 \\\\\n3 & 2 & -3\n\\end{pmatrix}_{2*3}\n\\]\nSi logra mirar el tamaño matricial es de \\(2\\times 3\\) tanto para C como para D, lo que no cumple con lo conformable cuando se realiza el proceso de la multiplicación matricial, lo que ocurre para esta parte es que se hará elemento a elemento p.e: \\(8\\times 4; -4\\times 2,...\\) y así sucesivamente. Es pertinente, siempre consolidar el cumplimiento de la característica de ser conformable, ya que garantiza que se pueda realizar la operación completa y de esta forma obtener los resultados deseados como por ejemplo en el caso de la regresión.\n\n### Podemos también tener y realizar operaciones con matrices\nC &lt;- matrix( c(8,-2,-4,7,6,0), nrow=2)\nD &lt;- matrix( c(4,3,2,2,-1,-3), nrow=2)\nC # Nos muestra la matriz realizada de C\n\n     [,1] [,2] [,3]\n[1,]    8   -4    6\n[2,]   -2    7    0\n\nD # Para observar los elementos de D\n\n     [,1] [,2] [,3]\n[1,]    4    2   -1\n[2,]    3    2   -3\n\n# Multiplicación elemento a elemento (no conformable)\nC*D\n\n     [,1] [,2] [,3]\n[1,]   32   -8   -6\n[2,]   -6   14    0\n\n# Transpuesta de una matriz:\n(G &lt;- t(D) )\n\n     [,1] [,2]\n[1,]    4    3\n[2,]    2    2\n[3,]   -1   -3\n\n# Forma correcta para MCO (conformable) de multiplicación:\n(H &lt;- C %*% G )\n\n     [,1] [,2]\n[1,]   18   -2\n[2,]    6    8\n\n# Para la Inversa o (-1) de matriz hay que usar solve\nsolve(H)\n\n            [,1]       [,2]\n[1,]  0.05128205 0.01282051\n[2,] -0.03846154 0.11538462",
    "crumbs": [
      "Parte 1",
      "6: Matrices y regresión múltiple"
    ]
  },
  {
    "objectID": "lecciones/unidad06.html#indicadores-anova",
    "href": "lecciones/unidad06.html#indicadores-anova",
    "title": "6: Matrices y regresión múltiple",
    "section": "Indicadores ANOVA",
    "text": "Indicadores ANOVA\nRecuerde que nuestros modelos todo el tiempo deben ser testeados. Un mecanismo para eso, es calcular sus respectivas métricas de varianza y analizar el error. Para eso vamos hacer un calculo manual:\n\n# Tomamos los ingredientes\nn &lt;- nrow(datos)            \nk &lt;- 2                        \n\ny_media &lt;- mean(datos$wage) # Promedio dependiente\n\n# Métricas duras\nSSR &lt;- sum(residuals(model1)^2)          # residuos\nTSS &lt;- sum((datos$wage - y_media)^2)     # Suma total modelo\nESS &lt;- sum((fitted(model1) - y_media)^2) # Suma explicada\n\n# Calculamos\nSER &lt;- sqrt(1/(n-k-1) * SSR)             # Error Estandar\nRsq &lt;- 1 - (SSR / TSS)                   # R(cuadrado)\nadj_Rsq &lt;- 1 - (n-1)/(n-k-1) * SSR/TSS   # R(Ajustado)\n\n# Resultados\nc(\"SER\" = SER, \"R2\" = Rsq, \"R2-Ajustado\" = adj_Rsq)\n\n        SER          R2 R2-Ajustado \n382.1921164   0.1085554   0.1066425",
    "crumbs": [
      "Parte 1",
      "6: Matrices y regresión múltiple"
    ]
  },
  {
    "objectID": "lecciones/unidad07.html",
    "href": "lecciones/unidad07.html",
    "title": "7: Variables cualitativas",
    "section": "",
    "text": "Las variables dummy son fundamentales en econometría porque permiten incorporar información cualitativa en los modelos de regresión. Estas variables, que toman valores de 0 y 1, permiten analizar cómo características no numéricas, como el género, la educación o la región geográfica, afectan la variable dependiente. Al usarlas, es posible medir diferencias de comportamiento entre grupos y capturar efectos específicos que no podrían representarse con variables continuas, facilitando un análisis más completo y realista de los datos.\n\n\n\n\nResumen\nEn esta ocasión, se muestra en el lenguaje de  R  como se debe trabajar la Regresion múltiple con variables dicótomas o binarias tipo (Dummy). La guía intenta servir como insumo para trabajar variables de tipo cualitativo en modelos de regresión cuando estas son explicativas. Se plantean varios ejemplos: primero, con una sola variable dummy, luego con mas controles y así, hasta llegar al ejemplo con dummies de umbrales. Se adiciona también el estudio de comparativos con la prueba F o global de parámetros.",
    "crumbs": [
      "Parte 2",
      "7: Variables cualitativas"
    ]
  },
  {
    "objectID": "lecciones/unidad07.html#footnotes",
    "href": "lecciones/unidad07.html#footnotes",
    "title": "7: Variables cualitativas",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLa base de datos es de un ejemplo del libro de Wooldridge y toma como referencia Black como raza afro descendiente, en ningún momento se hace incorrecta alusión a un irrespeto racial o despectivo al traducir literalmente ``Negro’’.↩︎\nEn la base esta categoría viene con datos de 1 para otras razas y de 2 para los Black, pero el tratamiento es el mismo en el modelo como si se tratara de cero y unos.↩︎\nSe muestra mas adelante en este mismo curso.↩︎",
    "crumbs": [
      "Parte 2",
      "7: Variables cualitativas"
    ]
  },
  {
    "objectID": "lecciones/unidad07.html#con-otros-controles-cuantitativos",
    "href": "lecciones/unidad07.html#con-otros-controles-cuantitativos",
    "title": "7: Variables cualitativas",
    "section": "Con otros controles cuantitativos",
    "text": "Con otros controles cuantitativos\nSi no se quiere trabajar con solo dummies sino también con otras variables \\(x's\\) pero de características cuantitativas y/o continuas, se puede estimar de esta manera: \\[Y_{i}=\\beta_{0} +\\beta_{i} D_{i}+ \\beta_{j} X_{j} + \\mu\\] Las interpretaciones no difieren, pero note que el parámetro de la constante \\(\\beta_0\\) ya no solo involucrará el promedio de la otra categoría sino también la de los otros elementos que inciden sobre la variable dependiente que están en \\(x_{i}\\).\n\n# Un modelo mas general con variable cualitativa y cuantitativa\nmd2&lt;-lm(wage~hours+black, data = Salarios)\nmd2result&lt;- huxreg(\"Tabla #2\" = md2)\nmd2result\n\n\n\nTabla #2\n\n(Intercept)1071.418 ***\n\n(80.883)   \n\nhours-1.826    \n\n(1.802)   \n\nblack-259.058 ***\n\n(38.895)   \n\nN935        \n\nR20.046    \n\nlogLik-6916.584    \n\nAIC13841.168    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nAl incluir variables explicativas sobre la regresión es notable que cambie la constante, pero que se mantenga -o que se modifique- el parámetro de la variable cualitativa es normal, ya que estamos en una regresión donde la dependiente es afectada ahora por mas variables explicativas. El modelo 1 incorpora solo la variable cualitativa como explicativa y el modelo 2 posee dos variables, la interpretación no varia, las personas ``Afro’’ ganan en promedio menos salario que las demás razas manteniendo constante las horas de trabajo.\nTambién es factible muchas veces que la variable cualitativa tenga cierto número de respuestas, como Estrato 1, Estrato 2, Estrato 3, etc., como también variables que involucran mas de una cualidad como por ejemplo: alto, bajo, mediano.} Además pueden ser variables diferenciadas por ocupación o por aquella variable que el investigador considere como importante. En R como en otros softwares, es importante decirles que se trabaja en formato de factor y es bueno hacerlo con etiquetas o labels, de lo contrario no mostrará el verdadero valor del parámetro que se asocia a esa variable.\n\n# Regresión por categorías \n# Inventemos una variable ahora\nset.seed(1239) # Código de replica\nocupacion&lt;-sample(1:5,935,replace=T) # Variable de ocupación \nSalarios$ocupacion&lt;-ocupacion\nSalarios$ocupacion&lt;- factor(Salarios$ocupacion, \n                             labels = c(\"Técnico\", \"Profesional\", \"Ejecutivo\",\"Auxiliar\", \"Pasante\"))                \ntable(Salarios$ocupacion)\n\n\n    Técnico Profesional   Ejecutivo    Auxiliar     Pasante \n        181         174         178         198         204 \n\nmd3&lt;-lm(wage~hours+black+ocupacion, data = Salarios)\nmd3result&lt;- huxreg(\"Tabla #3\" = md3)\nmd3result\n\n\n\nTabla #3\n\n(Intercept)1041.144 ***\n\n(86.879)   \n\nhours-1.838    \n\n(1.806)   \n\nblack-260.256 ***\n\n(38.869)   \n\nocupacionProfesional52.717    \n\n(41.976)   \n\nocupacionEjecutivo74.336    \n\n(41.755)   \n\nocupacionAuxiliar-9.167    \n\n(40.757)   \n\nocupacionPasante40.925    \n\n(40.389)   \n\nN935        \n\nR20.052    \n\nlogLik-6913.593    \n\nAIC13843.185    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nEl modelo 3 de la tabla anterior muestra la diferencia salarial por ocupación, siendo aquellos que pertenecen al grado  Ejecutivo ganan mas en promedio $ 74.34 dolares que las demás ocupaciones cuando la base es Técnico. Observe que el sistema de R ha omitido automáticamente una de las categorías (Técnico), para evitar el problema de la trampa de la dummy o multicolinealidad perfecta3 entre variables. Manualmente este hecho también puede ser tratado por el investigador y cambiar la omisión de esa variable y mostrar otra como base. Un ejemplo de código puede ser:\n\n#Regresión por categorías cambiando base\nSalarios$ocupacion&lt;-relevel(Salarios$ocupacion, \"Profesional\")\nmd4&lt;-lm(wage~hours+black+ocupacion, data = Salarios)\nmd4result&lt;- huxreg(\"Tabla #4\" = md4)\nmd4result\n\n\n\nTabla #4\n\n(Intercept)1093.861 ***\n\n(85.558)   \n\nhours-1.838    \n\n(1.806)   \n\nblack-260.256 ***\n\n(38.869)   \n\nocupacionTécnico-52.717    \n\n(41.976)   \n\nocupacionEjecutivo21.619    \n\n(42.124)   \n\nocupacionAuxiliar-61.884    \n\n(41.083)   \n\nocupacionPasante-11.792    \n\n(40.771)   \n\nN935        \n\nR20.052    \n\nlogLik-6913.593    \n\nAIC13843.185    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nLa siguiente forma solo brindará el promedio de salario que se gana cada ocupación como tal, -incluye a todas las categorías-, lo resultados son muy similares a los obtenidos anteriormente, solo que acá se hace sin comparación base. Recuerde siempre que todo modelo debe tener el término de la constante -así que-, es preferido siempre estimar de esta manera, con su respectiva constante o \\(\\beta_{0}\\).\n\nmd5&lt;-lm(wage~0+hours+black+ocupacion, data = Salarios)\nmd5result&lt;- huxreg(\"Tabla #5\" = md5)\nmd5result\n\n\n\nTabla #5\n\nhours-1.838    \n\n(1.806)   \n\nblack-260.256 ***\n\n(38.869)   \n\nocupacionProfesional1093.861 ***\n\n(85.558)   \n\nocupacionTécnico1041.144 ***\n\n(86.879)   \n\nocupacionEjecutivo1115.479 ***\n\n(85.269)   \n\nocupacionAuxiliar1031.977 ***\n\n(83.430)   \n\nocupacionPasante1082.069 ***\n\n(84.444)   \n\nN935        \n\nR20.857    \n\nlogLik-6913.593    \n\nAIC13843.185    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.",
    "crumbs": [
      "Parte 2",
      "7: Variables cualitativas"
    ]
  },
  {
    "objectID": "lecciones/unidad07.html#variable-dummy-con-variable-continua",
    "href": "lecciones/unidad07.html#variable-dummy-con-variable-continua",
    "title": "7: Variables cualitativas",
    "section": "Variable Dummy con variable Continua",
    "text": "Variable Dummy con variable Continua\nMuchas veces podemos hacer combinación entre una variable por grupo. Miremos lo siguiente:\n\nmd61&lt;-lm(wage~hours+black+black:hours, data = Salarios)\nmd61result&lt;- huxreg(\"Tabla #6.1\" = md61)\nmd61result\n\n\n\nTabla #6.1\n\n(Intercept)1066.406 ***\n\n(85.511)   \n\nhours-1.713    \n\n(1.908)   \n\nblack-214.498    \n\n(248.667)   \n\nhours:black-1.057    \n\n(5.827)   \n\nN935        \n\nR20.046    \n\nlogLik-6916.567    \n\nAIC13843.135    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nEl término de la interacción hours:black muestra solo el efecto parcial de ser Afro con el conjunto de horas que trabaja la persona. es decir, si queremos mirar solo el grupo de afros por nivel de horas, su efecto diferencial con respecto a los demás grupos de raza o género seria diferente en 1 dolar. Lo que quiere decir que tienden a pagarles menos de 1 dolar si esta fuera significativa, cuando solo se evalua por grupo. Para esta regresión no hay una diferencia significativa entre grupos de razas.\nMire ahora lo siguiente:\n\n# Modelo solo de afrodescendientes con horas\nlm(wage~hours, data=Salarios, subset=(black==1))\n\n\nCall:\nlm(formula = wage ~ hours, data = Salarios, subset = (black == \n    1))\n\nCoefficients:\n(Intercept)        hours  \n     851.91        -2.77  \n\n# Modelo sin afrodescendientes con horas de trabajo\nlm(wage~hours, data=Salarios, subset=(black==0))\n\n\nCall:\nlm(formula = wage ~ hours, data = Salarios, subset = (black == \n    0))\n\nCoefficients:\n(Intercept)        hours  \n   1066.406       -1.713  \n\n\nSin la interacción tendríamos que filtrar o hacer uso de siempre de la función de subconjuntos entre los datos, lo mismo de decir subset dentro de la opción de las personas que cumplen con cierta condición. Para el ejemplo notamos los parámetros que tiene una persona afro versus una de otra raza/genero.\nObserve ademas que si extraemos los coeficientes de esas regresiones qu realizamos tendríamos:\n\\[-2.77-(-1.713)=-1.057\\] Que es el efecto diferencial que hemos obtenido cuando hicimos la regresión original entre la interacción de la cuantitativa con la cualitativa.\nDesde luego depende también del investigador el establecimiento o formato de resultados que quiere dar a conocer en su trabajo investigativo.",
    "crumbs": [
      "Parte 2",
      "7: Variables cualitativas"
    ]
  },
  {
    "objectID": "lecciones/unidad07.html#variable-continua-con-variable-continua",
    "href": "lecciones/unidad07.html#variable-continua-con-variable-continua",
    "title": "7: Variables cualitativas",
    "section": "Variable Continua con variable Continua",
    "text": "Variable Continua con variable Continua\nEste proceso no es tan frecuente usarlo dentro de las regresiones para mirar efectos de grupos pero si para ver especificaciones de los modelos. La interacción en este caso es mas visual e incluso geométrico por lo de la linea de ajuste del modelo con el mapa de dispersión de variables. Sin embargo miremos solo la empleabilidad o una de las formas de hacerlo en R.\n\nmd62&lt;-lm(wage~hours+exper+exper:hours, data = Salarios)\nmd62result&lt;- huxreg(\"Tabla #6.2\" = md62)\nmd62result\n\n\n\nTabla #6.2\n\n(Intercept)1173.818 ***\n\n(231.960)   \n\nhours-4.913    \n\n(5.152)   \n\nexper-17.215    \n\n(19.294)   \n\nhours:exper0.393    \n\n(0.432)   \n\nN935        \n\nR20.001    \n\nlogLik-6937.905    \n\nAIC13885.809    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nNote que para este caso el parámetro de 0.33 no dice nada, aparte que no es significativo. Si quizas fuera significativo habría que mirar el grado de ajuste de la regresión. Recuerde que cuando tenemos ese tipo de variable o producto es casi similar cuando tendríamos una variable como por ejemplo \\(x^2\\) en el modelo de regresión, anteriormente ya se habia hablado de eso dentro del formato de la regresión.",
    "crumbs": [
      "Parte 2",
      "7: Variables cualitativas"
    ]
  },
  {
    "objectID": "lecciones/unidad07.html#dummy-umbral",
    "href": "lecciones/unidad07.html#dummy-umbral",
    "title": "7: Variables cualitativas",
    "section": "Dummy Umbral",
    "text": "Dummy Umbral\nEn algunas ocasiones también se pueden crear variables cualitativas a partir de un umbral (variable índice) o que se pueda ordenar de menor a mayor. Tomaremos un ejemplo con la variable de educación. Se establecerá como nivel básico aquellos que tengan una educación menor a 12 años y aquellos mayores a este nivel serán considerados como nivel Intermedio. Con esto se agrupa por grupos en una variable que es considerada continua a una simplemente cualitativa. Recuerde que el bachillerato completo solo se logra con 11 años aprobados, 5 de primaria y 6 de secundaria respectivamente.\n\n#Regresión con umbral o variable continua:\n#Se toma una variable cuantitativa o índice\nSalarios$umbral &lt;- ifelse(Salarios$educ &lt;12 ,1,0)\n#Modelo\nmd7&lt;-lm(wage~tenure+exper+black+umbral, data = Salarios)\nmd7result&lt;- huxreg(\"Tabla #7\" = md7)\nmd7result\n\n\n\nTabla #7\n\n(Intercept)921.935 ***\n\n(37.983)   \n\ntenure8.400 ** \n\n(2.616)   \n\nexper1.819    \n\n(3.132)   \n\nblack-228.215 ***\n\n(38.590)   \n\numbral-175.395 ***\n\n(45.674)   \n\nN935        \n\nR20.072    \n\nlogLik-6903.451    \n\nAIC13818.902    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nLas personas con un nivel básico ganan en promedio menos salario $175.4 que el nivel intermedio. La educación superior genera mejores retornos en salarios que la educación básica para las observaciones de este modelo. Se pueden establecer interacciones entre variables, pero eso siempre dependerá de lo que quiere responder cada investigador.",
    "crumbs": [
      "Parte 2",
      "7: Variables cualitativas"
    ]
  },
  {
    "objectID": "lecciones/unidad07.html#modelo-con-variable-dummy-ranking",
    "href": "lecciones/unidad07.html#modelo-con-variable-dummy-ranking",
    "title": "7: Variables cualitativas",
    "section": "Modelo con variable Dummy ranking",
    "text": "Modelo con variable Dummy ranking\nEn otras ocasiones se cuentan con variables que contienen información de tipo (“Examen”) o van en una relación de 0-100 o los valores específicos que han establecido los recopiladores de información. De tener esto y contar con grupos que han sacado específicamente un rango de valores, se pueden agrupar dentro de una variable dummy, que contendrá o dará el valor de 1 si las personas pertenecen a dicho grupo y de 0 si ocurre lo contrario.\n\\[\\begin{aligned}\nD_{1}=\\left\\{\\begin{matrix}\n1 & \\text{Si la persona sacó entre 0-5 en la prueba}\\\\\n0 & \\text{De lo contrario}\n\\end{matrix}\\right.\n&\n\\quad\nD_{2}=\\left\\{\\begin{matrix}\n1 & \\text{Si la persona sacó entre 6-10 en la prueba}\\\\\n0 & \\text{De lo contrario}\n\\end{matrix}\\right.\n\\\\\nD_{3}=\\left\\{\\begin{matrix}\n1 & \\text{Si la persona sacó entre 11-15 en la prueba}\\\\\n0 & \\text{De lo contrario}\n\\end{matrix}\\right.\n&\n\\quad\nD_{4}=\\left\\{\\begin{matrix}\n1 & \\text{Si la persona sacó entre 16-20 en la prueba}\\\\\n0 & \\text{De lo contrario}\n\\end{matrix}\\right.\n\\end{aligned}\\]\nDe esta forma y de acuerdo al número de cortes o grupos que establezca el investigador, tendrá grupos de comparación. Evitando la trampa de las dummies, se omite una variable que inmediatamente se irá al \\(\\beta_{0}\\) o constante y será el grupo de referencia para realizar las comparaciones respectivas.\n\n#Índices completos\n#Modelo con variable de notas o prueba de conocimientos\ntable(Salarios$KWW)\n\n\n12 13 14 15 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 \n 1  1  1  1  3  7  3 12  7 13 18 20 16 24 23 26 24 30 27 46 31 49 32 50 49 57 \n39 40 41 42 43 44 45 46 47 48 49 50 51 54 55 56 \n48 57 45 41 23 35 30 17 18 20 11  9  6  2  1  1 \n\n#Definen puntos de corte\ncorte&lt;-c(20,25,30,35,40,45,50,60)\n\n#se crea la variable rankiada\nSalarios$ranking&lt;-cut(Salarios$KWW, corte)\n\n#Una tabla\ntable(Salarios$ranking)\n\n\n(20,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,60] \n     74     127     185     261     174      75      10 \n\n\nCon esto ya usted sabe o podrá usar las observaciones por ranking de datos y puntos de corte que automáticamente el algoritmo ya ha hecho para mostrar. A continuación la estimación en un modelo especifico\n\n#Modelo rankeado\nmd8&lt;-lm(wage~exper+black+ranking, data = Salarios)\nmd8result&lt;- huxreg(\"Tabla #8\" = md8)\nmd8result\n\n\n\nTabla #8\n\n(Intercept)845.407 ***\n\n(55.631)   \n\nexper0.444    \n\n(2.895)   \n\nblack-182.933 ***\n\n(40.110)   \n\nranking(25,30]21.305    \n\n(55.385)   \n\nranking(30,35]22.709    \n\n(52.607)   \n\nranking(35,40]138.102 ** \n\n(50.690)   \n\nranking(40,45]254.785 ***\n\n(53.542)   \n\nranking(45,50]381.919 ***\n\n(63.114)   \n\nranking(50,60]619.472 ***\n\n(128.224)   \n\nN906        \n\nR20.139    \n\nlogLik-6658.624    \n\nAIC13337.248    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n#Si quiere cambiar de referencia o base (**Opcional**)\nSalarios$ranking&lt;-relevel(Salarios$ranking, \"(50,60]\")\n\nUna forma de interpretar esto, es tomar una referencia de la variable de Ranking y leer teniendo en cuenta como referencia el primer grupo. Para este caso, aquellos que cuya prueba han sacado un rango entre 50 y 60 puntos ganan en promedio $ 619.46 de salario mas que el grupo que solo sacó en la prueba entre 20 y 25 puntos (grupo base).",
    "crumbs": [
      "Parte 2",
      "7: Variables cualitativas"
    ]
  },
  {
    "objectID": "lecciones/unidad07.html#comparando-entre-grupos",
    "href": "lecciones/unidad07.html#comparando-entre-grupos",
    "title": "7: Variables cualitativas",
    "section": "Comparando entre grupos",
    "text": "Comparando entre grupos\nLa prueba F también sirve para hacer comparaciones entre grupos. Suponga que el objetivo de una investigación es comparar el salario de una persona que pertenece al grupo de “Afrodescendientes” con todas las “otras razas” pero teniendo en cuenta todas y cada una de las variables asociadas a la educación, experiencia y fidelidad con el actual empleador. Para esto, se requiere realizar una prueba F.\n\n# Modelo comparando dos grupos \n# Modelo original\nmodr&lt;-lm(wage~educ+exper+tenure, data = Salarios)\nsummary(modr)\n\n\nCall:\nlm(formula = wage ~ educ + exper + tenure, data = Salarios)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-866.29 -249.23  -51.07  189.62 2190.01 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -276.240    106.702  -2.589 0.009778 ** \neduc          74.415      6.287  11.836  &lt; 2e-16 ***\nexper         14.892      3.253   4.578 5.33e-06 ***\ntenure         8.257      2.498   3.306 0.000983 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 374.3 on 931 degrees of freedom\nMultiple R-squared:  0.1459,    Adjusted R-squared:  0.1431 \nF-statistic:    53 on 3 and 931 DF,  p-value: &lt; 2.2e-16\n\nmodo&lt;-lm(wage~black*(educ+exper+tenure), data = Salarios) \nsummary(modo)\n\n\nCall:\nlm(formula = wage ~ black * (educ + exper + tenure), data = Salarios)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-895.5 -241.7  -46.8  184.5 2159.6 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -220.842    112.811  -1.958   0.0506 .  \nblack         331.709    357.360   0.928   0.3535    \neduc           72.738      6.571  11.069  &lt; 2e-16 ***\nexper          15.470      3.482   4.443 9.96e-06 ***\ntenure          5.874      2.629   2.235   0.0257 *  \nblack:educ    -40.646     23.175  -1.754   0.0798 .  \nblack:exper    -6.423      9.120  -0.704   0.4815    \nblack:tenure   12.726      7.836   1.624   0.1047    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 369.5 on 927 degrees of freedom\nMultiple R-squared:  0.1712,    Adjusted R-squared:  0.1649 \nF-statistic: 27.35 on 7 and 927 DF,  p-value: &lt; 2.2e-16\n\n# Prueba entre grupos con la F\nlinearHypothesis(modo, matchCoefs(modo, \"black\"))\n\n\n\nRes.DfRSSDfSum of SqFPr(&gt;F)\n\n9311.3e+08                  \n\n9271.27e+0843.86e+067.071.32e-05\n\n\n\n\nDebe mirar que en este caso, si existen diferencias considerables con respecto a los “Afros” y los demás grupos de referencia, sobre todo en lo que tiene que ver con la educación, ya que las diferencias son mucho mas marcadas. La prueba F en este caso permite rechazar a un nivel de significancia del 99% la no relevancia y/o importancia de estas variables dentro del modelo.",
    "crumbs": [
      "Parte 2",
      "7: Variables cualitativas"
    ]
  }
]